{
  "createdAt": "2025-12-19T14:44:18.372Z",
  "id": "8LDaqMPpSFj2AggT",
  "name": "sw_expert",
  "description": null,
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "usuario_id"
            },
            {
              "name": "chat_id"
            },
            {
              "name": "data_conversa"
            },
            {
              "name": "usr_nome_preferencia"
            }
          ]
        }
      },
      "id": "start-v4",
      "name": "start",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -4240,
        1120
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT c.id, c.resumo_conversa, c.tem_reflexao, c.mensagens, c.total_palavras_usuario, u.nome_preferencia\nFROM usr_chat c JOIN usuarios u ON u.id = c.usuario_id WHERE c.id = $1::uuid;",
        "options": {
          "queryReplacement": "={{ [$json.chat_id] }}"
        }
      },
      "id": "buscar-dados-v4",
      "name": "Buscar Dados Chat",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -4048,
        1120
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "model": "google/gemini-3-flash-preview",
        "options": {
          "maxTokens": 1000,
          "temperature": 0.2
        }
      },
      "id": "llm-resumo-v4",
      "name": "LLM Resumo",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -3968,
        1440
      ],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\"tem_contexto\":true,\"tem_reflexao\":true,\"justificativa\":\"string\",\"total_palavras\":150,\"resumo_atualizado\":\"string\"}"
      },
      "id": "parser-resumo-v4",
      "name": "Parser Resumo",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -3712,
        1424
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<input>\n<user_name>{{ $('start').item.json.usr_nome_preferencia }}</user_name>\n<messages>{{ JSON.stringify($json.mensagens) }}</messages>\n</input>\n\nAnalise as mensagens e retorne JSON.\n\n<output_format>\n{\"tem_contexto\":boolean,\"tem_reflexao\":boolean,\"total_palavras\":number,\"justificativa\":\"string\",\"resumo\":\"string\"}\n</output_format>\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=<role>Analista de conversas terapêuticas</role>\n\n<objective>Sintetizar conversa em resumo temático + avaliar profundidade reflexiva</objective>\n\n<rules>\n- Analise mensagens com autor=\"usuario\" e use o autor=\"agente\" para completar o contexto\n- NUNCA use o termo usuário, sempre usar {{ $('start').item.json.usr_nome_preferencia }}\n- Máximo 1000 palavras no resumo\n- Retorne APENAS JSON válido\n- Organize o resumo por temas usando Markdown\n- Conte e retone sempre a quatidade total de palavras do usuário\n</rules>\n\n\n<summary_example>\n\n\n</summary_example>\n\n\n<themes>Emocional | Trabalho | Relacionamentos | Saúde | Finanças | Objetivos | Reflexões</themes>\n\n<output_format>\n{\"tem_contexto\":boolean,\"tem_reflexao\":boolean,\"total_palavras\":number,\"justificativa\":\"string\",\"resumo\":\"string\"}\n</output_format>\n\n",
          "maxIterations": 3
        }
      },
      "id": "agent-resumo-v4",
      "name": "resumo conversa",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -3872,
        1120
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "cond-ctx",
              "leftValue": "={{ $json.output.tem_contexto }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            },
            {
              "id": "22246224-bd1c-4caa-87b4-f6288d18c97a",
              "leftValue": "={{ $json.output.tem_reflexao }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "if-contexto-v4",
      "name": "Tem Contexto?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -3536,
        1120
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "DELETE FROM usuarios_sabotadores WHERE chat_id = $1::uuid;\nDELETE FROM usuarios_emocoes WHERE chat_id = $1::uuid;\nDELETE FROM usuarios_humor_energia WHERE chat_id = $1::uuid;\nDELETE FROM usuarios_perfis WHERE chat_id = $1::uuid;\nDELETE FROM insights WHERE chat_id = $1::uuid;",
        "options": {
          "queryReplacement": "={{ [$('start').first().json.chat_id] }}"
        }
      },
      "id": "delete-dados-v4",
      "name": "DELETE Dados Anteriores",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2832,
        576
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "UPDATE usr_chat SET resumo_conversa = $2, tem_reflexao = $3, status = 'finalizado', horario_fim = NOW(), atualizado_em = NOW(), total_palavras_usuario = $4 WHERE id = $1::uuid RETURNING id, status;",
        "options": {
          "queryReplacement": "={{ [$('start').first().json.chat_id, $('resumo conversa').first().json.output.resumo_atualizado, $('resumo conversa').first().json.output.tem_reflexao, $('resumo conversa').first().json.output.total_palavras] }}"
        }
      },
      "id": "atualizar-chat-v4",
      "name": "Atualizar usr_chat",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -3200,
        1088
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "return [{json: {processado: false, motivo: 'Contexto insuficiente', chat_id: $input.first().json.chat_id}}];"
      },
      "id": "ctx-insuf-v4",
      "name": "contexto_insuficiente",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -3296,
        1328
      ]
    },
    {
      "parameters": {
        "jsCode": "return [{json: {processado: true, motivo: 'OK', chat_id: $('start').first().json.chat_id}}];"
      },
      "id": "retorno-ok-v4",
      "name": "Retorno Sucesso",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -2960,
        1088
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT jsonb_agg(jsonb_build_object('codigo', codigo, 'nome', nome) ORDER BY codigo) AS catalogo FROM sabotadores_catalogo;",
        "options": {}
      },
      "id": "buscar-catalogo-v4",
      "name": "Buscar Catalogo Sabotadores",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -2128,
        640
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "model": "google/gemini-2.5-flash",
        "options": {
          "maxTokens": 1500,
          "temperature": 0.2
        }
      },
      "id": "llm-sabotadores-v4",
      "name": "LLM Sabotadores",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -1856,
        848
      ],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Identifique sabotadores internos na conversa.\n\n<input>\n<messages>{{ JSON.stringify($('Buscar Dados Chat').first().json.mensagens) }}</messages>\n<user_name>{{ $('start').first().json.usr_nome_preferencia }}</user_name>\n<catalogo>{{ JSON.stringify($json.catalogo) }}</catalogo>\n</input>\n\n<output_format>\n{\"sabotadores_detectados\":[{\"codigo\":1,\"intensidade\":75,\"contexto\":\"relacionamentos\",\"frases_gatilho\":[\"frase1\"],\"insights\":\"impacto\",\"confiabilidade\":90,\"apelido\":\"Sr. X\",\"contramedida\":\"acao\"}]}\n</output_format>",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=<role>Especialista em Sabotadores Internos (Shirzad Chamine)</role>\n\n<objective>Detectar padrões de pensamento sabotadores com evidências textuais</objective>\n\n<rules>\n- Use Mensagens do agente para entender o contexto, mas o foco são as mensagens do usuário\n- Use APENAS códigos 1-10 do catálogo fornecido\n- Intensidade: escala 0-100 (não 0-10)\n- Mínimo intensidade 30 para incluir\n- Frases gatilho: 2-4 trechos CURTOS (max 15 palavras)\n- Se nenhum detectado, retorne array vazio\n</rules>\n\n<scale>\n0-20: muito fraca | 21-40: fraca | 41-60: moderada | 61-80: forte | 81-100: muito forte\n</scale>\n\n<output_format>\n{\"sabotadores_detectados\":[{\"codigo\":1,\"intensidade\":75,\"contexto\":\"relacionamentos\",\"frases_gatilho\":[\"frase1\"],\"insights\":\"impacto\",\"confiabilidade\":90,\"apelido\":\"Sr. X\",\"contramedida\":\"acao\"}]}\n</output_format>",
          "maxIterations": 3
        }
      },
      "id": "agent-sabotadores-v4",
      "name": "sabotadores",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -1824,
        640
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH input AS (SELECT $1::uuid as usuario_id, $2::uuid as chat_id, $3::jsonb as arr),\ndata AS (SELECT i.usuario_id, i.chat_id, sc.id as sabotador_id,\n  (s->>'intensidade')::int as intensidade, (s->>'contexto')::varchar(100) as contexto,\n  (s->>'insights')::text as insights, (s->>'apelido')::varchar(50) as apelido,\n  (s->>'contramedida')::text as contramedida\n  FROM input i, jsonb_array_elements(i.arr) s\n  JOIN sabotadores_catalogo sc ON sc.codigo = (s->>'codigo')::int\n  WHERE (s->>'intensidade')::int >= 30)\nINSERT INTO usuarios_sabotadores (usuario_id, chat_id, sabotador_id, intensidade_media,\n  intensidade_acumulada_dia, total_deteccoes_dia, total_deteccoes, contexto_principal,\n  insight_atual, apelido_personalizado, contramedida_ativa, sabotador_predominante, data_ultima_atividade)\nSELECT usuario_id, chat_id, sabotador_id, intensidade, intensidade, 1, 1, contexto,\n  insights, apelido, contramedida, true, CURRENT_DATE FROM data\nRETURNING id, sabotador_id;",
        "options": {
          "queryReplacement": "={{ [$('start').first().json.usuario_id, $('start').first().json.chat_id, JSON.stringify($json.output.sabotadores_detectados || [])] }}"
        }
      },
      "id": "gravar-sabotadores-v4",
      "name": "Gravar Sabotadores",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1520,
        640
      ],
      "alwaysOutputData": true,
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 1200,
          "temperature": 0.2
        }
      },
      "id": "llm-panas-v4",
      "name": "LLM PANAS",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -2096,
        1904
      ],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<input>\n<messages>{{ JSON.stringify($('Buscar Dados Chat').first().json.mensagens) }}</messages>\n</input>\n\nClassifique emoções presentes na conversa.\n\n<output_format>\n{\"emocoes_detectadas\":[{\"emocao_id\":\"slug\",\"nome_pt\":\"nome\",\"intensidade\":number,\"contexto\":\"POSITIVA|NEGATIVA|NEUTRA\",\"evidencias\":[\"trecho1\"]}],\"classificacao_panas\":\"positiva|negativa|neutra\",\"justificativa_panas\":\"motivo\",\"confianca_analise\":number}\n</output_format>",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=<role>Classificador Emocional (Plutchik + PANAS)</role>\n\n<objective>Identificar emoções primárias e classificar afeto global</objective>\n\n<vocabulary>\njoy=Alegria(+) | trust=Confiança(+) | anticipation=Expectativa(+)\nsadness=Tristeza(-) | fear=Medo(-) | anger=Raiva(-) | disgust=Nojo(-)\nsurprise=Surpresa(~)\n</vocabulary>\n\n<rules>\n- Use APENAS os 8 emocao_id acima\n- Intensidade: 0-100 (só inclua se >= 45)\n- Contexto: POSITIVA|NEGATIVA|NEUTRA (determinado pela emoção, não pelo tom)\n- Evidências: 1-5 trechos literais\n- Uma emoção por tipo (consolide múltiplas ocorrências)\n</rules>\n\n<panas_rules>\n- Só emoções com intensidade >= 45 participam\n- Se diferença positivas vs negativas < 20%: NEUTRA\n- Se total = 0: NEUTRA\n</panas_rules>\n\n<output_format>\n{\"emocoes_detectadas\":[{\"emocao_id\":\"slug\",\"nome_pt\":\"nome\",\"intensidade\":number,\"contexto\":\"POSITIVA|NEGATIVA|NEUTRA\",\"evidencias\":[\"trecho1\"]}],\"classificacao_panas\":\"positiva|negativa|neutra\",\"justificativa_panas\":\"motivo\",\"confianca_analise\":number}\n</output_format>\n\n",
          "maxIterations": 3
        }
      },
      "id": "agent-panas-v4",
      "name": "panas e emocoes",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -2080,
        1712
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH ej AS (SELECT $1::uuid AS usuario_id, $2::uuid AS chat_id, $3::date AS dt, jsonb_array_elements($4::jsonb) AS e)\nINSERT INTO usuarios_emocoes (usuario_id, chat_id, emocao_id, intensidade, intensidade_acumulada,\n  ocorrencias_dia, detectado_em, contexto, evidencias, emocao_pt)\nSELECT usuario_id, chat_id, (e->>'emocao_id')::varchar(20), (e->>'intensidade')::int,\n  (e->>'intensidade')::int, 1, dt, (e->>'contexto')::varchar(100),\n  (e->>'evidencias')::jsonb, (e->>'nome_pt')::varchar(20) FROM ej WHERE (e->>'intensidade')::int >= 45\nON CONFLICT (chat_id, emocao_id) DO UPDATE SET\n  ocorrencias_dia = usuarios_emocoes.ocorrencias_dia + 1,\n  intensidade_acumulada = usuarios_emocoes.intensidade_acumulada + EXCLUDED.intensidade,\n  intensidade = (usuarios_emocoes.intensidade_acumulada + EXCLUDED.intensidade) / (usuarios_emocoes.ocorrencias_dia + 1)\nRETURNING id, emocao_id;",
        "options": {
          "queryReplacement": "={{ [$('start').first().json.usuario_id, $('start').first().json.chat_id, ((v) => v ? new Date(v).toISOString().slice(0,10) : null)($('start').first().json.data_conversa), JSON.stringify($json.output.emocoes_detectadas || [])] }}"
        }
      },
      "id": "gravar-emocoes-v4",
      "name": "Gravar Emocoes",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1728,
        1712
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 800,
          "temperature": 0.2
        }
      },
      "id": "llm-humor-v4",
      "name": "LLM Humor",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -2128,
        2336
      ],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<input>\n<messages>{{ JSON.stringify($('Buscar Dados Chat').first().json.mensagens) }}</messages>\n<user_name>{{ $('start').first().json.usr_nome_preferencia }}</user_name>\n</input>\n\nAnalise humor e energia do usuário.\n\n<output_format>\n{\"humor_dia\": number, \"energia_nivel\": number, \"variacao_humor\": \"string\", \"variacao_energia\": \"string\", \"periodo_dia\": \"string\", \"justificativa_humor\": \"string (max 200 chars)\", \"justificativa_energia\": \"string (max 200 chars)\", \"evidencias_textuais\": [\"2-5 trechos curtos\"], \"confianca_analise\": number}\n</output_format>\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=<role>Analista de Humor e Energia</role>\n\n<objective>Detectar estado emocional e nível de energia a partir da conversa</objective>\n\n<rules>\n- Analise APENAS mensagens com autor=\"usuario\"\n- Se sem evidência clara: humor=5, energia=5\n- Use nome do usuário nas justificativas\n</rules>\n\n<scales>\nhumor_dia: 1-10 (1=péssimo, 5=neutro, 10=excelente)\nenergia_nivel: 1-10 (1=exausto, 5=normal, 10=energizado)\nconfianca_analise: 0-100\n</scales>\n\n<allowed_values>\nperiodo_dia: madrugada|manha|tarde|noite|nao_identificado\nvariacao_humor: estavel|ascendente|descendente|oscilatoria\nvariacao_energia: estavel|ascendente|descendente|oscilatoria\n</allowed_values>\n\n<output_format>\n{\"humor_dia\": number, \"energia_nivel\": number, \"variacao_humor\": \"string\", \"variacao_energia\": \"string\", \"periodo_dia\": \"string\", \"justificativa_humor\": \"string (max 200 chars)\", \"justificativa_energia\": \"string (max 200 chars)\", \"evidencias_textuais\": [\"2-5 trechos curtos\"], \"confianca_analise\": number}\n</output_format>",
          "maxIterations": 3
        }
      },
      "id": "agent-humor-v4",
      "name": "humor e energia",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -2112,
        2128
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO usuarios_humor_energia (usuario_id, chat_id, data_registro, hora_registro,\n  periodo_dia, humor_dia, humor_acumulado, energia_nivel, energia_acumulada,\n  ocorrencias_dia, variacao_humor, variacao_energia, justificativa_humor,\n  justificativa_energia, evidencias_textuais, confianca_analise)\nVALUES ($1::uuid, $2::uuid, $3::date, CURRENT_TIME, $4, $5::int, $5::int, $6::int, $6::int,\n  1, $7, $8, $9, $10, $11::jsonb, $12::int)\nON CONFLICT (chat_id) DO UPDATE SET\n  ocorrencias_dia = usuarios_humor_energia.ocorrencias_dia + 1,\n  humor_acumulado = usuarios_humor_energia.humor_acumulado + EXCLUDED.humor_dia,\n  energia_acumulada = usuarios_humor_energia.energia_acumulada + EXCLUDED.energia_nivel,\n  humor_dia = (usuarios_humor_energia.humor_acumulado + EXCLUDED.humor_dia) / (usuarios_humor_energia.ocorrencias_dia + 1),\n  energia_nivel = (usuarios_humor_energia.energia_acumulada + EXCLUDED.energia_nivel) / (usuarios_humor_energia.ocorrencias_dia + 1),\n  detectado_em = NOW()\nRETURNING id, humor_dia, energia_nivel;",
        "options": {
          "queryReplacement": "={{ [$('start').first().json.usuario_id, $('start').first().json.chat_id, ((v) => v ? new Date(v).toISOString().slice(0,10) : null)($('start').first().json.data_conversa), $json.output.periodo_dia, $json.output.humor_dia, $json.output.energia_nivel, $json.output.variacao_humor, $json.output.variacao_energia, JSON.stringify($json.output.justificativa_humor), JSON.stringify($json.output.justificativa_energia), JSON.stringify($json.output.evidencias_textuais || []), $json.output.confianca_analise] }}"
        }
      },
      "id": "gravar-humor-v4",
      "name": "Gravar Humor",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1776,
        2128
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "HDTrSrJiBIv2FFks",
          "mode": "list"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "usr_id": "={{ $('start').first().json.usuario_id }}"
          }
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "buscar-hist-bf-v4",
      "name": "Buscar Historico BigFive",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        -2096,
        112
      ],
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "functionCode": "const s = $items('start')[0]?.json ?? {};\nconst h = $items('Buscar Historico BigFive').map(i => i.json).filter(Boolean);\nconst fmt = v => { if (!v) return null; const d = new Date(v); return isNaN(d) ? v : d.toISOString().slice(0,10); };\nconst hist = h.map(e => ({data: fmt(e.data_conversa), resumo: e.resumo_conversa || ''})).filter(e => e.data || e.resumo).sort((a,b) => a.data < b.data ? 1 : -1);\nconst resumo = hist.length ? hist.slice(0,3).map(e => `- ${e.data}: ${e.resumo}`).join('\\n') : 'Sem hist\\u00f3rico.';\nreturn [{json: {...s, historico_resumo: resumo}}];"
      },
      "id": "prep-ctx-bf-v4",
      "name": "Preparar Contexto BigFive",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -1888,
        112
      ]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 1500,
          "temperature": 0.2
        }
      },
      "id": "llm-bf-v4",
      "name": "LLM BigFive",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -1712,
        320
      ],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<input>\n<historico>{{ $json.historico_resumo }}</historico>\n<messages>{{ JSON.stringify($('Buscar Dados Chat').first().json.mensagens) }}</messages>\n<user_name>{{ $json.usr_nome_preferencia }}</user_name>\n</input>\n\nEstime perfil Big Five (OCEAN) do usuário.\n\n<output_format>\n{\"big_five\":{\"openness\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"conscientiousness\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"extraversion\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"agreeableness\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"neuroticism\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]}},\"perfil_primario\":\"openness|conscientiousness|extraversion|agreeableness|neuroticism|misto\",\"resumo_perfil\":\"max 400 chars\",\"insuficiente\":boolean}\n</output_format>",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=<role>Especialista em Big Five (OCEAN)</role>\n\n<objective>Inferir tendências de personalidade com evidências textuais</objective>\n\n<traits>\nO=Openness (curiosidade, ideias novas)\nC=Conscientiousness (organização, disciplina)\nE=Extraversion (energia social)\nA=Agreeableness (empatia, cooperação)\nN=Neuroticism (sensibilidade a estresse)\n</traits>\n\n<rules>\n- Use APENAS mensagens com autor=\"usuario\"\n- Histórico: apenas contexto, não use como evidência\n- Score e confiabilidade: 0-100 (50=neutro)\n- Evidências: 2-4 trechos curtos (max 15 palavras)\n- Se insuficiente: score=50, confiabilidade<=40\n- NÃO faça diagnósticos clínicos\n</rules>\n\n<perfil_primario_rule>\nSe diferença entre 1º e 2º < 5 pontos: \"misto\"\nSenão: traço com maior score\n</perfil_primario_rule>\n\n<output_format>\n{\"big_five\":{\"openness\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"conscientiousness\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"extraversion\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"agreeableness\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]},\"neuroticism\":{\"score\":n,\"confiabilidade\":n,\"evidencias\":[]}},\"perfil_primario\":\"openness|conscientiousness|extraversion|agreeableness|neuroticism|misto\",\"resumo_perfil\":\"max 400 chars\",\"insuficiente\":boolean}\n</output_format>\n",
          "maxIterations": 3
        }
      },
      "id": "agent-bf-v4",
      "name": "Big Five",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -1696,
        112
      ]
    },
    {
      "parameters": {
        "functionCode": "const s = $items('start')[0]?.json ?? {};\nconst p = $json.output ?? {};\nconst traits = ['openness','conscientiousness','extraversion','agreeableness','neuroticism'];\nconst norm = v => { const n = Number(v); return Number.isFinite(n) ? Math.min(100, Math.max(0, Math.round(n >= 0 && n <= 1 ? n * 100 : n))) : null; };\nconst scores = traits.map(t => ({id: t, score: norm(p.big_five?.[t]?.score), conf: norm(p.big_five?.[t]?.confiabilidade)}));\nconst sorted = [...scores].sort((a,b) => (b.score||0) - (a.score||0));\nlet primary = p.perfil_primario;\nif (!primary || primary === 'misto' || !traits.includes(primary)) primary = sorted[0]?.id;\nconst secondary = sorted.find(e => e.id !== primary)?.id || sorted[1]?.id;\nconst avgConf = scores.length ? Math.round(scores.reduce((a,e) => a + (e.conf||0), 0) / scores.length) : null;\nlet dt = s.data_conversa ? new Date(s.data_conversa).toISOString().slice(0,10) : new Date().toISOString().slice(0,10);\nconst r = {usuario_id: s.usuario_id, chat_id: s.chat_id, data_conversa: dt, perfil_original: p.perfil_primario, perfil_primario: primary, perfil_secundario: secondary, resumo_perfil: p.resumo_perfil, insuficiente: Boolean(p.insuficiente), confianca_media: avgConf, raw_resposta: p};\ntraits.forEach(t => { r[`score_${t}`] = norm(p.big_five?.[t]?.score); r[`confianca_${t}`] = norm(p.big_five?.[t]?.confiabilidade); });\nreturn [{json: r}];"
      },
      "id": "prep-reg-bf-v4",
      "name": "Preparar Registro BigFive",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        -1360,
        112
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO usuarios_perfis (usuario_id, chat_id, data_conversa, perfil_original, perfil_primario, perfil_secundario, resumo_perfil, insuficiente, score_openness, score_conscientiousness, score_extraversion, score_agreeableness, score_neuroticism, confianca_openness, confianca_conscientiousness, confianca_extraversion, confianca_agreeableness, confianca_neuroticism, confianca_media, raw_resposta, criado_em, atualizado_em)\nVALUES ($1::uuid, $2::uuid, $3::date, $4, $5, $6, $7, $8::boolean, $9::int, $10::int, $11::int, $12::int, $13::int, $14::int, $15::int, $16::int, $17::int, $18::int, $19::int, $20::jsonb, NOW(), NOW())\nON CONFLICT (chat_id) DO UPDATE SET perfil_primario = EXCLUDED.perfil_primario, perfil_secundario = EXCLUDED.perfil_secundario, resumo_perfil = EXCLUDED.resumo_perfil, insuficiente = EXCLUDED.insuficiente, score_openness = EXCLUDED.score_openness, score_conscientiousness = EXCLUDED.score_conscientiousness, score_extraversion = EXCLUDED.score_extraversion, score_agreeableness = EXCLUDED.score_agreeableness, score_neuroticism = EXCLUDED.score_neuroticism, confianca_media = EXCLUDED.confianca_media, raw_resposta = EXCLUDED.raw_resposta, atualizado_em = NOW()\nRETURNING id, perfil_primario;",
        "options": {
          "queryReplacement": "={{ [$json.usuario_id, $json.chat_id, $json.data_conversa, $json.perfil_original, $json.perfil_primario, $json.perfil_secundario, $json.resumo_perfil, $json.insuficiente === true, $json.score_openness, $json.score_conscientiousness, $json.score_extraversion, $json.score_agreeableness, $json.score_neuroticism, $json.confianca_openness, $json.confianca_conscientiousness, $json.confianca_extraversion, $json.confianca_agreeableness, $json.confianca_neuroticism, $json.confianca_media, $json.raw_resposta || {}] }}"
        }
      },
      "id": "gravar-bf-v4",
      "name": "Gravar BigFive",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1168,
        112
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 1500,
          "temperature": 0.3
        }
      },
      "id": "llm-insights-v4",
      "name": "LLM Insights",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -2096,
        1376
      ],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<input>\n<messages>{{ JSON.stringify($('Buscar Dados Chat').first().json.mensagens) }}</messages>\n<user_name>{{ $('start').first().json.usr_nome_preferencia }}</user_name>\n<date>{{ $('start').first().json.data_conversa }}</date>\n</input>\n\n\nGere 1 insight com feedback sanduíche.\n\n<output_format>\n[{\"tipo\":\"string\",\"categoria\":\"string\",\"titulo\":\"3-4 palavras\",\"icone\":\"emoji\",\"prioridade\":\"string\",\"resumo_situacao\":\"30-50 palavras\",\"feedback_positivo\":\"string\",\"feedback_desenvolvimento\":\"string\",\"feedback_motivacional\":\"string\",\"recursos_sugeridos\":[{\"tipo\":\"string\",\"nome\":\"string\",\"descricao\":\"string\",\"aplicacao_pratica\":\"string\"}],\"baseado_em\":[\"evidencia1\",\"evidencia2\"]}]\n</output_format>",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=<role>Psicólogo especialista em desenvolvimento pessoal</role>\n\n<objective>Gerar insight acionável com feedback sanduíche + recursos práticos</objective>\n\n<tools>\nget_user_insight: consulta insights anteriores para evitar repetição\n</tools>\n\n<allowed_values>\ncategoria: comportamental|emocional|social|cognitivo\ntipo: padrao|melhoria|positivo|alerta\nprioridade: alta|media|baixa\ntipo_recurso: tecnica|conceito|leitura|pratica|reflexao\n\nCRITICO: Use somente os valores definidos\n</allowed_values>\n\n<feedback_sanduiche>\n1. feedback_positivo: reconheça forças (20-30 palavras)\n2. feedback_desenvolvimento: padrão que merece atenção (30-40 palavras)\n3. feedback_motivacional: esperança + próximos passos (20-30 palavras)\n</feedback_sanduiche>\n\n<rules>\n- Base TUDO no relatado (sem suposições)\n- Use APENAS valores permitidos acima\n- Evite repetir insights anteriores\n- 2-4 recursos práticos por insight\n</rules>\n\n\n\n\n",
          "maxIterations": 3
        }
      },
      "id": "agent-insights-v4",
      "name": "insights",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        -2080,
        1168
      ]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "WITH d AS (\n  SELECT\n    $1::uuid as uid,\n    $2::uuid as cid,\n    e->>'tipo' as tipo,\n    e->>'categoria' as cat,\n    e->>'titulo' as tit,\n    e->>'resumo_situacao' as res,\n    e->>'icone' as ico,\n    CASE\n      WHEN translate(lower(coalesce(e->>'prioridade','')),\n        'áàâãäéèêëíìîïóòôõöúùûüç',\n        'aaaaaeeeeiiiiooooouuuuc'\n      ) IN ('alta','media','baixa')\n      THEN translate(lower(coalesce(e->>'prioridade','')),\n        'áàâãäéèêëíìîïóòôõöúùûüç',\n        'aaaaaeeeeiiiiooooouuuuc'\n      )\n      ELSE 'media'\n    END as pri,\n    e->>'feedback_positivo' as fp,\n    e->>'feedback_desenvolvimento' as fd,\n    e->>'feedback_motivacional' as fm,\n    e->'recursos_sugeridos' as rec,\n    e->'baseado_em' as base\n  FROM jsonb_array_elements($3::jsonb) e\n  LIMIT 1\n)\nINSERT INTO insights (usuario_id, chat_id, tipo, categoria, titulo, descricao, icone, prioridade, ativo, resumo_situacao, feedback_positivo, feedback_desenvolvimento, feedback_motivacional, recursos_sugeridos, baseado_em)\nSELECT uid, cid, tipo, cat, tit, res, ico, pri, true, res, fp, fd, fm, rec, ARRAY(SELECT jsonb_array_elements_text(base)) FROM d\nON CONFLICT (chat_id) DO UPDATE SET\n  tipo = EXCLUDED.tipo,\n  categoria = EXCLUDED.categoria,\n  titulo = EXCLUDED.titulo,\n  prioridade = EXCLUDED.prioridade,\n  resumo_situacao = EXCLUDED.resumo_situacao,\n  feedback_positivo = EXCLUDED.feedback_positivo,\n  feedback_desenvolvimento = EXCLUDED.feedback_desenvolvimento,\n  feedback_motivacional = EXCLUDED.feedback_motivacional,\n  recursos_sugeridos = EXCLUDED.recursos_sugeridos,\n  criado_em = NOW()\nRETURNING id, titulo;",
        "options": {
          "queryReplacement": "={{ [$('start').first().json.usuario_id, $('start').first().json.chat_id, JSON.stringify($json.output || [])] }}"
        }
      },
      "id": "gravar-insights-v4",
      "name": "Gravar Insights",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [
        -1664,
        1168
      ],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "W0i3ufnDIIcx75ez",
          "mode": "list"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "usuario_id": "={{ $('start').first().json.usuario_id }}",
            "chat_id": "={{ $('start').first().json.chat_id }}",
            "data_conversa": "={{ $('start').first().json.data_conversa }}"
          }
        },
        "options": {
          "waitForSubWorkflow": false
        }
      },
      "id": "exec-xp-v4",
      "name": "Executar XP Conversas",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        -2416,
        64
      ]
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "QyIfpyS7zBCOe8AC",
          "mode": "list"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "usuario_id": "={{ $('start').first().json.usuario_id }}",
            "chat_id": "={{ $('start').first().json.chat_id }}"
          }
        },
        "options": {
          "waitForSubWorkflow": false
        }
      },
      "id": "exec-quest-v4",
      "name": "Executar Expert Quests",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [
        -1280,
        640
      ]
    },
    {
      "parameters": {
        "content": "## Big Five - Perfil de personalidade",
        "height": 544,
        "width": 1680
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2608,
        -64
      ],
      "id": "11746fc9-ccab-49a7-8730-423c52a0c3f7",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "## Sabotadores",
        "height": 544,
        "width": 1296
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2240,
        528
      ],
      "id": "5e6d1772-3490-4feb-8698-446f0a10c9ed",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "## Insights",
        "height": 464,
        "width": 864
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2240,
        1104
      ],
      "id": "341ee263-c1c6-48f4-9c34-f9e9719f57e3",
      "name": "Sticky Note3"
    },
    {
      "parameters": {
        "content": "## Emoções - Panas",
        "height": 448,
        "width": 704
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2240,
        1600
      ],
      "id": "f3bc3c41-c3e8-4534-9633-0373a8b21946",
      "name": "Sticky Note4"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"big_five\": {\n    \"openness\": {\"score\": 62, \"confiabilidade\": 78, \"evidencias\": [\"gosto de explorar ideias novas\", \"procuro alternativas criativas\"]},\n    \"conscientiousness\": {\"score\": 54, \"confiabilidade\": 65, \"evidencias\": [\"monitorei meu plano\", \"organizei meus passos\"]},\n    \"extraversion\": {\"score\": 41, \"confiabilidade\": 60, \"evidencias\": [\"prefiro ficar na minha\", \"evitei encontros\"]},\n    \"agreeableness\": {\"score\": 70, \"confiabilidade\": 72, \"evidencias\": [\"procurei conciliar\", \"quero evitar conflito\"]},\n    \"neuroticism\": {\"score\": 58, \"confiabilidade\": 68, \"evidencias\": [\"fiquei ansioso com perdas\", \"preocupação constante\"]}\n  },\n  \"perfil_primario\": \"agreeableness\",\n  \"resumo_perfil\": \"Pessoa colaborativa, aberta a diálogos e soluções conjuntas, mantendo equilíbrio em disciplina e energia social.\",\n  \"insuficiente\": false\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -1536,
        320
      ],
      "id": "2102c308-59d3-49f5-af31-9f92a292c0ac",
      "name": "Parser Bigfive"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\"sabotadores_detectados\":[{\"codigo\":1,\"intensidade\":75,\"contexto\":\"relacionamentos\",\"frases_gatilho\":[\"frase1\"],\"insights\":\"impacto\",\"confiabilidade\":90,\"apelido\":\"Sr. X\",\"contramedida\":\"acao\"}]}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -1664,
        848
      ],
      "id": "64ac8a4a-5bf3-47e7-9fa0-03f780a002b3",
      "name": "Parser sabotadores"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[{\"tipo\":\"padrao\",\"categoria\":\"emocional\",\"titulo\":\"Titulo\",\"icone\":\"emoji\",\"prioridade\":\"media\",\"resumo_situacao\":\"resumo\",\"feedback_positivo\":\"positivo\",\"feedback_desenvolvimento\":\"desenvolvimento\",\"feedback_motivacional\":\"motivacional\",\"recursos_sugeridos\":[{\"tipo\":\"tecnica\",\"nome\":\"nome\",\"descricao\":\"desc\",\"aplicacao_pratica\":\"aplicacao\"}],\"baseado_em\":[\"evidencia\"]}]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -1920,
        1376
      ],
      "id": "d1c10c7a-0f4b-4571-be13-f5b413c8e78f",
      "name": "Parser Insights"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\"emocoes_detectadas\":[{\"emocao_id\":\"sadness\",\"nome_pt\":\"tristeza\",\"intensidade\":85,\"contexto\":\"NEGATIVA\",\"evidencias\":[\"trecho1\"]}],\"classificacao_panas\":\"negativa\",\"justificativa_panas\":\"motivo\",\"confianca_analise\":90}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -1920,
        1904
      ],
      "id": "82ff5290-b55a-429b-9a51-e727183bd612",
      "name": "Parser PANAS"
    },
    {
      "parameters": {
        "content": "## Humor e energia",
        "height": 448,
        "width": 704
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -2240,
        2080
      ],
      "id": "f738d0e9-6133-4d88-b92a-94ed5e4c97cb",
      "name": "Sticky Note5"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\"humor_dia\":6,\"energia_nivel\":6,\"variacao_humor\":\"estavel\",\"variacao_energia\":\"estavel\",\"periodo_dia\":\"tarde\",\"justificativa_humor\":\"motivo\",\"justificativa_energia\":\"motivo\",\"evidencias_textuais\":[\"trecho1\"],\"confianca_analise\":80}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        -1952,
        2336
      ],
      "id": "29c45485-592d-4efc-928e-bb2552486ab3",
      "name": "Parser Humor"
    },
    {
      "parameters": {
        "content": "## Resumo da conversa",
        "height": 544,
        "width": 1600
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -4320,
        1040
      ],
      "id": "1f122961-a4a5-48e3-8da8-228e55646e18",
      "name": "Sticky Note6"
    }
  ],
  "connections": {
    "start": {
      "main": [
        [
          {
            "node": "Buscar Dados Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Buscar Dados Chat": {
      "main": [
        [
          {
            "node": "resumo conversa",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Resumo": {
      "main": [
        []
      ],
      "ai_languageModel": [
        [
          {
            "node": "resumo conversa",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Parser Resumo": {
      "main": [
        []
      ],
      "ai_outputParser": [
        [
          {
            "node": "resumo conversa",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "resumo conversa": {
      "main": [
        [
          {
            "node": "Tem Contexto?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Tem Contexto?": {
      "main": [
        [
          {
            "node": "DELETE Dados Anteriores",
            "type": "main",
            "index": 0
          },
          {
            "node": "Atualizar usr_chat",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "contexto_insuficiente",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Atualizar usr_chat": {
      "main": [
        [
          {
            "node": "Retorno Sucesso",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "DELETE Dados Anteriores": {
      "main": [
        [
          {
            "node": "Buscar Catalogo Sabotadores",
            "type": "main",
            "index": 0
          },
          {
            "node": "panas e emocoes",
            "type": "main",
            "index": 0
          },
          {
            "node": "humor e energia",
            "type": "main",
            "index": 0
          },
          {
            "node": "Buscar Historico BigFive",
            "type": "main",
            "index": 0
          },
          {
            "node": "insights",
            "type": "main",
            "index": 0
          },
          {
            "node": "Executar XP Conversas",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Buscar Catalogo Sabotadores": {
      "main": [
        [
          {
            "node": "sabotadores",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Sabotadores": {
      "main": [
        []
      ],
      "ai_languageModel": [
        [
          {
            "node": "sabotadores",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "sabotadores": {
      "main": [
        [
          {
            "node": "Gravar Sabotadores",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM PANAS": {
      "main": [
        []
      ],
      "ai_languageModel": [
        [
          {
            "node": "panas e emocoes",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "panas e emocoes": {
      "main": [
        [
          {
            "node": "Gravar Emocoes",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Humor": {
      "main": [
        []
      ],
      "ai_languageModel": [
        [
          {
            "node": "humor e energia",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "humor e energia": {
      "main": [
        [
          {
            "node": "Gravar Humor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Buscar Historico BigFive": {
      "main": [
        [
          {
            "node": "Preparar Contexto BigFive",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Preparar Contexto BigFive": {
      "main": [
        [
          {
            "node": "Big Five",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM BigFive": {
      "main": [
        []
      ],
      "ai_languageModel": [
        [
          {
            "node": "Big Five",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Big Five": {
      "main": [
        [
          {
            "node": "Preparar Registro BigFive",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Preparar Registro BigFive": {
      "main": [
        [
          {
            "node": "Gravar BigFive",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM Insights": {
      "main": [
        []
      ],
      "ai_languageModel": [
        [
          {
            "node": "insights",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "insights": {
      "main": [
        [
          {
            "node": "Gravar Insights",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Gravar Sabotadores": {
      "main": [
        [
          {
            "node": "Executar Expert Quests",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parser Bigfive": {
      "ai_outputParser": [
        [
          {
            "node": "Big Five",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Parser sabotadores": {
      "ai_outputParser": [
        [
          {
            "node": "sabotadores",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Parser Insights": {
      "ai_outputParser": [
        [
          {
            "node": "insights",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Parser PANAS": {
      "ai_outputParser": [
        [
          {
            "node": "panas e emocoes",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Parser Humor": {
      "ai_outputParser": [
        [
          {
            "node": "humor e energia",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "availableInMCP": false
  },
  "staticData": null,
  "meta": null,
  "pinData": {
    "start": [
      {
        "json": {
          "usuario_id": "4bb8706a-7886-4ccb-8263-ff51aaafaafa",
          "chat_id": "a5d6b35c-b781-48f2-9df3-e93ef76631c3",
          "data_conversa": "2025-12-20T00:00:00.000Z",
          "usr_nome_preferencia": "Davi"
        },
        "pairedItem": {
          "item": 0
        }
      }
    ]
  },
  "activeVersionId": null,
  "shared": [
    {
      "createdAt": "2025-12-19T14:44:18.372Z",
      "role": "workflow:owner",
      "workflowId": "8LDaqMPpSFj2AggT",
      "projectId": "u1M57XAwIiLpPwjp",
      "project": {
        "createdAt": "2025-09-16T16:13:20.606Z",
        "id": "u1M57XAwIiLpPwjp",
        "name": "Aldo Santos <lindualdo@hotmail.com>",
        "type": "personal",
        "icon": null,
        "description": null,
        "projectRelations": [
          {
            "createdAt": "2025-09-16T16:13:20.606Z",
            "userId": "fa864d51-475e-4765-b3b4-12788525a3e6",
            "projectId": "u1M57XAwIiLpPwjp",
            "user": {
              "createdAt": "2025-09-16T16:13:20.056Z",
              "id": "fa864d51-475e-4765-b3b4-12788525a3e6",
              "email": "lindualdo@hotmail.com",
              "firstName": "Aldo",
              "lastName": "Santos",
              "personalizationAnswers": {
                "version": "v4",
                "personalization_survey_submitted_at": "2025-09-16T16:22:10.583Z",
                "personalization_survey_n8n_version": "1.108.1"
              },
              "settings": {
                "userActivated": true,
                "firstSuccessfulWorkflowId": "jUAvu7DUAzyqZhJd",
                "userActivatedAt": 1758041156747,
                "easyAIWorkflowOnboarded": true,
                "dismissedCallouts": {
                  "preBuiltAgentsModalCallout": true
                },
                "npsSurvey": {
                  "responded": true,
                  "lastShownAt": 1759918723295
                }
              },
              "disabled": false,
              "mfaEnabled": false,
              "isPending": false
            }
          }
        ]
      }
    }
  ],
  "tags": [],
  "activeVersion": null
}
