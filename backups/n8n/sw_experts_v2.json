{
  "name": "sw_experts_v2",
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            { "name": "usuario_id", "type": "string" },
            { "name": "chat_id", "type": "string" },
            { "name": "mensagens", "type": "string" },
            { "name": "data_conversa", "type": "string" },
            { "name": "usr_nome_preferencia", "type": "string" },
            { "name": "total_interactions", "type": "number" }
          ]
        }
      },
      "id": "start-001",
      "name": "start",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [0, 500]
    },
    {
      "parameters": {
        "content": "## sw_experts_v2 - Hub Consolidado\n\n### Fluxo\n1. **Resumo Conversa** (IA) ‚Üí valida contexto\n2. **IF** tem_contexto = true\n3. **Experts em paralelo:**\n   - Sabotadores (busca cat√°logo + IA + grava)\n   - PANAS/Emo√ß√µes (IA + grava)\n   - Humor/Energia (IA + grava)\n   - Big Five (busca hist√≥rico + IA + grava)\n   - Insights (IA + grava)\n4. **Atualiza usr_chat** (resumo, status)\n5. **Log final** em log_experts\n\n### Vantagens\n- Contexto compartilhado\n- Economia de tokens\n- Menos overhead de chamadas\n- Manuten√ß√£o centralizada\n\n### Regras\n- Se tem_contexto=false ‚Üí pula experts\n- Cada expert grava em sua tabela\n- Log √∫nico por execu√ß√£o"
      },
      "id": "sticky-001",
      "name": "Regras sw_experts_v2",
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [-400, 0],
      "width": 380,
      "height": 500
    },

    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Buscar dados do chat e resumo existente\nSELECT\n  c.id,\n  c.resumo_conversa,\n  c.tem_reflexao,\n  c.total_palavras_usuario,\n  u.nome_preferencia\nFROM usr_chat c\nJOIN usuarios u ON u.id = c.usuario_id\nWHERE c.id = $1::uuid;",
        "options": {
          "queryReplacement": "={{ [$json.chat_id] }}"
        }
      },
      "id": "pg-buscar-dados",
      "name": "Buscar Dados Chat",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [220, 500],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "promptType": "define",
        "text": "=Voc√™ √© um especialista em an√°lise e s√≠ntese de conversas.\n\n**NOME DO USU√ÅRIO:** {{ $('start').item.json.usr_nome_preferencia }}\n\n**RESUMO ANTERIOR (se existir):**\n```\n{{ $('Buscar Dados Chat').item.json.resumo_conversa || 'Nenhum resumo anterior' }}\n```\n\n**NOVAS MENSAGENS (delta):**\n```\n{{ $('start').item.json.mensagens }}\n```\n\n---\n\n**SUA TAREFA:**\n\n1. **ANALISAR O DELTA**\n   - As novas mensagens t√™m conte√∫do relevante para an√°lise?\n   - H√° informa√ß√µes novas ou √© apenas conversa casual/repetitiva?\n\n2. **INCORPORAR AO RESUMO EXISTENTE**\n   - N√ÉO substitua o resumo anterior\n   - ADICIONE as novas informa√ß√µes relevantes\n   - Elimine redund√¢ncias (se algo j√° est√° no resumo, n√£o repita)\n\n3. **ORGANIZAR POR TEMAS**\n   Agrupe as informa√ß√µes nos temas abaixo (use apenas os que tiverem conte√∫do):\n   - **Emocional**: sentimentos, humor, estado mental\n   - **Trabalho**: carreira, projetos, produtividade\n   - **Relacionamentos**: fam√≠lia, amigos, social\n   - **Sa√∫de**: bem-estar f√≠sico, sono, energia\n   - **Finan√ßas**: dinheiro, investimentos, trading\n   - **Objetivos**: metas, planos, decis√µes\n   - **Reflex√µes**: insights, aprendizados, autoconhecimento\n\n4. **AVALIAR REFLEX√ÉO**\n   - tem_reflexao = true SE o usu√°rio demonstrou autoconhecimento, fez conex√µes entre eventos e emo√ß√µes, ou analisou seus padr√µes\n   - tem_reflexao = false SE apenas relatou fatos superficialmente\n\n5. **AVALIAR CONTEXTO**\n   - tem_contexto = true SE h√° conte√∫do suficiente para an√°lises de emo√ß√µes, sabotadores, humor\n   - tem_contexto = false SE conversa foi muito superficial ou casual\n\n---\n\n**RETORNE APENAS ESTE JSON:**\n```json\n{\n  \"tem_contexto\": true,\n  \"tem_reflexao\": true,\n  \"justificativa\": \"breve explica√ß√£o\",\n  \"total_palavras_delta\": 150,\n  \"resumo_atualizado\": \"## Emocional\\n- item 1\\n- item 2\\n\\n## Trabalho\\n- item 1\\n\\n## Reflex√µes\\n- insight importante\"\n}\n```",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "Voc√™ √© um especialista em an√°lise e s√≠ntese de conversas terap√™uticas e de desenvolvimento pessoal.\n\nREGRAS CR√çTICAS:\n1. NUNCA substitua o resumo anterior - sempre INCORPORE\n2. Elimine redund√¢ncias - n√£o repita informa√ß√µes j√° presentes\n3. Organize SEMPRE por temas usando markdown (## Tema)\n4. Seja objetivo e direto\n5. M√°ximo de 800 palavras no resumo total\n6. Preserve contexto emocional e insights importantes\n7. Retorne APENAS JSON estruturado"
        }
      },
      "id": "agent-resumo",
      "name": "1. Resumo Conversa",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [460, 500]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 1500,
          "temperature": 0.2
        }
      },
      "id": "llm-resumo",
      "name": "LLM Resumo",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [380, 720],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"tem_contexto\": true,\n  \"tem_reflexao\": true,\n  \"justificativa\": \"string\",\n  \"total_palavras_delta\": 150,\n  \"resumo_atualizado\": \"string\"\n}"
      },
      "id": "parser-resumo",
      "name": "Parser Resumo",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [540, 720]
    },

    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict" },
          "conditions": [
            {
              "id": "condition-contexto",
              "leftValue": "={{ $json.output.tem_contexto }}",
              "rightValue": true,
              "operator": { "type": "boolean", "operation": "equals" }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "if-contexto",
      "name": "Tem Contexto?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [720, 500]
    },

    {
      "parameters": {
        "operation": "executeQuery",
        "query": "SELECT id, nome, descricao FROM sabotadores_catalogo ORDER BY nome;",
        "options": {}
      },
      "id": "pg-catalogo-sabotadores",
      "name": "Buscar Cat√°logo Sabotadores",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [960, 200],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Analise a conversa e identifique sabotadores internos segundo Shirzad Chamine.\n\n**CONVERSA:**\n```json\n{{ $('start').first().json.mensagens }}\n```\nNome do usu√°rio: {{ $('start').first().json.usr_nome_preferencia }}\n\n**SABOTADORES V√ÅLIDOS (use APENAS estes IDs):**\n{{ $('Buscar Cat√°logo Sabotadores').all().map(s => `- **${s.json.nome}** (${s.json.id}): ${s.json.descricao || ''}`).join('\\n') }}\n\n**CR√çTICO: sabotador_id DEVE ser EXATAMENTE um dos IDs acima**\n\n**SUA TAREFA:**\n1. Leia APENAS mensagens do usu√°rio (autor: \"usuario\")\n2. Identifique sabotadores ativos (m√≠nimo intensidade 30)\n3. Para cada sabotador:\n   - sabotador_id: EXATAMENTE um dos IDs da lista acima\n   - Intensidade: 0-100\n   - Contexto: vida_pessoal|profissional|financeiro|relacionamentos|saude|familia\n   - Frases gatilho: 2-4 frases CURTAS (m√°x 15 palavras)\n   - Insights: como impacta (use nome do usu√°rio na 3¬™ pessoa)\n   - Confiabilidade: 0-100\n   - Apelido: curto e humanizado (ex: \"Sr. Ansioso\")\n   - Contramedida: UMA a√ß√£o pr√°tica\n\n**REGRAS:**\n- Intensidade 0-100 (N√ÉO 0-10)\n- Apenas sabotadores com intensidade ‚â• 30\n- Se n√£o houver sabotadores, retorne array vazio\n- Retorne APENAS JSON estruturado",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "Voc√™ √© especialista em detectar sabotadores internos segundo Shirzad Chamine.\n\nSeu trabalho:\n1. Identificar padr√µes de pensamento autodestrutivos\n2. Avaliar intensidades na escala 0-100 (IMPORTANTE: N√ÉO use 0-10)\n3. Extrair TRECHOS CURTOS E ESPEC√çFICOS como frases gatilho (n√£o textos longos)\n4. Classificar contextos corretamente\n5. Criar apelidos humanizados e contramedidas pr√°ticas\n\nEscala de intensidade 0-100:\n- 0-20: muito fraca\n- 21-40: fraca  \n- 41-60: moderada\n- 61-80: forte\n- 81-100: muito forte\n\nFRASES GATILHO:\n- Devem ser trechos CURTOS (m√°ximo 15 palavras)\n- Extraia 2-4 frases espec√≠ficas que evidenciam o sabotador\n- N√ÉO copie o texto inteiro\n- Exemplo bom: \"me senti desprezado\", \"ela n√£o gostava mais de mim\"\n- Exemplo ruim: texto completo de 50+ palavras\n\nSeja criterioso: apenas inclua sabotadores com evid√™ncias claras e intensidade ‚â• 30.\n\nRetorne SEMPRE JSON v√°lido.",
          "maxIterations": 3
        }
      },
      "id": "agent-sabotadores",
      "name": "2. Analisar Sabotadores",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [1200, 200]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 2000,
          "temperature": 0.2
        }
      },
      "id": "llm-sabotadores",
      "name": "LLM Sabotadores",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [1120, 420],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"sabotadores_detectados\": [\n    {\n      \"sabotador_id\": \"critico\",\n      \"nome_pt\": \"Cr√≠tico\",\n      \"intensidade\": 75,\n      \"contexto\": \"relacionamentos\",\n      \"frases_gatilho\": [\n        \"me senti desprezado\",\n        \"ela n√£o gostava mais de mim\",\n        \"n√£o encontrei algu√©m que vale a pena\"\n      ],\n      \"insights\": \"Autocr√≠tica intensa sobre valor pessoal e capacidade de ser amado. Padr√£o recorrente de d√∫vida sobre pr√≥prio valor em relacionamentos.\",\n      \"confiabilidade\": 90,\n      \"apelido\": \"Sr. Exigente\",\n      \"contramedida\": \"Praticar autocompaix√£o: falar consigo como falaria com um amigo querido por 3 minutos\"\n    }\n  ]\n}",
        "autoFix": true
      },
      "id": "parser-sabotadores",
      "name": "Parser Sabotadores",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [1280, 420]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Inserir sabotadores detectados\nWITH sabotadores_input AS (\n  SELECT \n    $1::uuid as usuario_id,\n    $2::uuid as chat_id,\n    $3::jsonb as sabotadores_array\n)\nINSERT INTO usuarios_sabotadores (\n  usuario_id,\n  chat_id,\n  sabotador_id,\n  intensidade_media,\n  contexto_principal,\n  insight_atual,\n  total_deteccoes,\n  apelido_personalizado,\n  contramedida_ativa,\n  sabotador_predominante,\n  data_ultima_atividade\n)\nSELECT \n  si.usuario_id,\n  si.chat_id,\n  (sabotador->>'sabotador_id')::varchar(30),\n  (sabotador->>'intensidade')::integer,\n  (sabotador->>'contexto')::varchar(100),\n  (sabotador->>'insights')::text,\n  1,\n  (sabotador->>'apelido')::varchar(50),\n  (sabotador->>'contramedida')::text,\n  true,\n  CURRENT_DATE\nFROM sabotadores_input si,\n     jsonb_array_elements(si.sabotadores_array) as sabotador\nWHERE (sabotador->>'intensidade')::integer >= 30\nRETURNING id, sabotador_id, intensidade_media;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.usuario_id,\n  $('start').first().json.chat_id,\n  JSON.stringify($json.output.sabotadores_detectados || [])\n] }}"
        }
      },
      "id": "pg-gravar-sabotadores",
      "name": "Gravar Sabotadores",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [1440, 200],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "promptType": "define",
        "text": "=### User Prompt  \nDADOS DA CONVERSA:  \nMensagens: {{ $('start').first().json.mensagens }}\n\nExecute a an√°lise emocional conforme descrito no System Prompt identifique todas as emo√ß√µes de Plutchik presentes, atribua intensidade, contexto e evid√™ncia, e ent√£o classifique o sentimento global da conversa como POSITIVA, NEGATIVA ou NEUTRA. Retorne **somente** o JSON estruturado conforme as regras.\n\n",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=### System Prompt ‚Äî Classificador Emocional (Plutchik + PANAS)\n\nVoc√™ √© um especialista em an√°lise emocional com base nas **oito emo√ß√µes prim√°rias de Robert Plutchik** e em agrega√ß√£o de afeto inspirada no **PANAS**.\n\n---\n\n#### üéØ Objetivo\nLer **todas as mensagens da conversa** e identificar **as emo√ß√µes prim√°rias presentes**, classificando-as conforme o modelo Plutchik e agregando o resultado segundo a escala PANAS.\n\n---\n\n#### üß† Tarefa passo a passo\n1. Analise **todas as mensagens** fornecidas.\n2. Detecte quais emo√ß√µes prim√°rias est√£o presentes (apenas as listadas abaixo).\n3. Para cada emo√ß√£o detectada, retorne os campos:\n   - `emocao_id`: slug obrigat√≥rio (ver **Vocabul√°rio permitido**).\n   - `intensidade`: n√∫mero inteiro de **0 a 100**.\n   - `contexto`: valor fixo (**POSITIVA**, **NEGATIVA** ou **NEUTRA**) conforme tabela de polaridade.\n   - `evidencias`: lista de **trechos literais da conversa** (1‚Äì5 itens) que justifiquem a detec√ß√£o.\n\n4. Ap√≥s listar todas as emo√ß√µes, gere um objeto `classificacao_geral` conforme as regras PANAS descritas abaixo.\n\n---\n\n#### üî§ Vocabul√°rio permitido\n| emocao_id | Nome (PT)      | Polaridade |\n|------------|----------------|-------------|\n| joy        | Alegria        | POSITIVA    |\n| trust      | Confian√ßa      | POSITIVA    |\n| anticipation| Expectativa   | POSITIVA    |\n| sadness    | Tristeza       | NEGATIVA    |\n| fear       | Medo           | NEGATIVA    |\n| anger      | Raiva          | NEGATIVA    |\n| disgust    | Nojo           | NEGATIVA    |\n| surprise   | Surpresa       | NEUTRA      |\n\n> **Proibi√ß√£o:** Nenhum outro valor al√©m dos 8 acima pode aparecer em `emocao_id`.\n\n---\n\n#### ‚öñÔ∏è Mapeamento de polaridade\nUse **apenas** os seguintes contextos fixos:\n- POSITIVA ‚Üí joy, trust, anticipation  \n- NEGATIVA ‚Üí sadness, fear, anger, disgust  \n- NEUTRA ‚Üí surprise  \n\n> O `contexto` n√£o √© inferido do tom, e sim **determinado diretamente** pela emo√ß√£o.\n\n---\n\n#### üìä Regras de agrega√ß√£o e classifica√ß√£o global\n- Somente emo√ß√µes com `intensidade ‚â• 45` participam do c√°lculo PANAS.  \n- Contagens:\n  - `positivas`: n¬∫ de emo√ß√µes POSITIVAS\n  - `negativas`: n¬∫ de emo√ß√µes NEGATIVAS\n  - `neutras`: n¬∫ de emo√ß√µes NEUTRAS  \n  - `total`: soma de todas\n- Percentuais (0‚Äì100, uma casa decimal):  \n  - `percentual_positivas = positivas / total * 100`  \n  - `percentual_negativas = negativas / total * 100`  \n  - `percentual_neutras = neutras / total * 100`\n- Se `total = 0`, todos os valores devem ser 0 e `classificacao_global = \"NEUTRA\"`.\n- Regras PANAS:\n  - Se a diferen√ßa entre `percentual_positivas` e `percentual_negativas` for **menor que 20%**, classifique como **NEUTRA**.  \n  - Caso contr√°rio, prevalece o maior percentual: **POSITIVA** ou **NEGATIVA**.\n\n---\n\n#### üß© Regras adicionais\n- Sempre use o campo `emocao_id` com **um dos slugs permitidos**.  \n- Se detectar nuances como **culpa**, **vergonha**, **orgulho**, **ansiedade** ou **gratid√£o**, mapeie para a emo√ß√£o prim√°ria **mais pr√≥xima** (ex.: culpa ‚Üí tristeza, orgulho ‚Üí alegria).  \n- Antes de responder, **revise toda a lista `emocoes_detectadas`**:\n  - Se algum item estiver fora do vocabul√°rio permitido, **corrija ou remova**.  \n  - Garanta que `intensidade` esteja entre 0 e 100.  \n  - Garanta que `contexto` corresponda √† polaridade da emo√ß√£o.  \n  - Garanta que `evidencias` seja um **array literal de frases reais**.  \n\n---\n\n#### üßæ Boas pr√°ticas\n- Detecte cada emo√ß√£o **no m√°ximo uma vez**. Consolide m√∫ltiplas ocorr√™ncias em um √∫nico item, somando intensidade e reunindo as evid√™ncias mais fortes.  \n- Ordene `emocoes_detectadas` por `intensidade` **decrescente**.  \n- Evite interpreta√ß√µes ou narrativas; apenas relacione evid√™ncias textuais.\n\n---\n\n#### üßÆ Estrutura de sa√≠da esperada\nRetorne **somente um JSON v√°lido**, sem texto livre, Markdown ou coment√°rios.",
          "maxIterations": 5
        }
      },
      "id": "agent-panas",
      "name": "3. Analisar Emo√ß√µes PANAS",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [960, 400]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 1500,
          "temperature": 0.2
        }
      },
      "id": "llm-panas",
      "name": "LLM PANAS",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [880, 620],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"emocoes_detectadas\": [\n    {\n      \"emocao_id\": \"sadness\",\n      \"nome_pt\": \"tristeza\",\n      \"intensidade\": 85,\n      \"contexto\": \"NEGATIVA\",\n      \"evidencias\": [\"saudade\", \"solid√£o\", \"ang√∫stia\", \"me senti desprezado\"]\n    },\n    {\n      \"emocao_id\": \"anticipation\",\n      \"nome_pt\": \"expectativa\",\n      \"intensidade\": 40,\n      \"contexto\": \"POSITIVA\",\n      \"evidencias\": [\"projetos pessoais\", \"acompanhamento terap√™utico\"]\n    },\n    {\n      \"emocao_id\": \"fear\",\n      \"nome_pt\": \"medo\",\n      \"intensidade\": 50,\n      \"contexto\": \"NEGATIVA\",\n      \"evidencias\": [\"preocupa√ß√£o\", \"inseguran√ßa\"]\n    }\n  ],\n  \"classificacao_panas\": \"negativa\",\n  \"justificativa_panas\": \"Predomin√¢ncia de tristeza (85) relacionada a perda, solid√£o e rejei√ß√£o. Expectativa presente mas em menor intensidade.\",\n  \"confianca_analise\": 90\n}",
        "autoFix": true
      },
      "id": "parser-panas",
      "name": "Parser PANAS",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [1040, 620]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Inserir m√∫ltiplas emo√ß√µes detectadas\nWITH emocoes_json AS (\n  SELECT \n    $1::uuid AS usuario_id,\n    $2::uuid AS chat_id,\n    $3::date AS data_conversa,\n    jsonb_array_elements($4::jsonb) AS emocao\n)\nINSERT INTO usuarios_emocoes (\n  usuario_id,\n  chat_id,\n  emocao_id,\n  intensidade,\n  detectado_em,\n  contexto,\n  evidencias,\n  emocao_pt\n)\nSELECT \n  ej.usuario_id,\n  ej.chat_id,\n  (ej.emocao->>'emocao_id')::varchar(20),\n  (ej.emocao->>'intensidade')::integer,\n  ej.data_conversa,\n  (ej.emocao->>'contexto')::varchar(100),\n  (ej.emocao->>'evidencias')::jsonb,\n  (ej.emocao->>'nome_pt')::varchar(20)\nFROM emocoes_json ej\nWHERE (ej.emocao->>'intensidade')::integer >= 45\nRETURNING id, emocao_id, intensidade;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.usuario_id,\n  $('start').first().json.chat_id,\n  ((v) => v ? new Date(v).toISOString().slice(0,10) : null)($('start').first().json.data_conversa),\n  JSON.stringify($json.output.emocoes_detectadas || [])\n] }}"
        }
      },
      "id": "pg-gravar-emocoes",
      "name": "Gravar Emo√ß√µes",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [1200, 400],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "promptType": "define",
        "text": "=Analise a conversa completa abaixo e detecte o HUMOR e ENERGIA do usu√°rio com base APENAS no que foi dito.\n\n**CONVERSA COMPLETA:**\n```json\n{{ $('start').first().json.mensagens }}\n```\n\nUser name: {{ $('start').first().json.usr_nome_preferencia }}\n\n**SUA TAREFA:**\n1. Leia TODA a conversa (autor: \"usuario\" apenas)\n2. Detecte o HUMOR GERAL do dia (1-10):\n   - 1-3: muito negativo (tristeza profunda, desesperan√ßa)\n   - 4-5: negativo (des√¢nimo, frustra√ß√£o)\n   - 6-7: neutro/misto (altos e baixos)\n   - 8-9: positivo (animado, esperan√ßoso)\n   - 10: muito positivo (euf√≥rico, excelente)\n\n3. Detecte o N√çVEL DE ENERGIA (1-10):\n   - 1-3: exausto, sem for√ßas\n   - 4-5: cansado, baixa energia\n   - 6-7: energia moderada\n   - 8-9: disposto, energizado\n   - 10: muito energizado, hiperativo\n\n4. Identifique VARIA√á√ÉO durante a conversa:\n   - estavel: humor/energia constante\n   - ascendente: melhora ao longo da conversa\n   - descendente: piora ao longo da conversa\n   - oscilatoria: alterna muito\n\n5. Detecte PER√çODO DO DIA (se mencionado):\n   - manha, tarde, noite, madrugada\n   - Se n√£o mencionado: \"nao_identificado\"\n\n**REGRAS:**\n- Base a an√°lise APENAS nas palavras do usu√°rio\n- Considere: tom emocional, vocabul√°rio, descri√ß√µes de atividades\n- Seja preciso e realista\n- Justifique brevemente cada score\n- Ao gerar a justificativa e resumo das conversas relacionados com o humor, use sempre o nome do usu√°rio: {{ $('start').first().json.usr_nome_preferencia }}\n- Caso o nome do usu√°rio n√£o seja informado, use o termo Usu√°rio\n**RETORNE APENAS O JSON ESTRUTURADO**",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "Voc√™ √© um especialista em an√°lise de humor e energia em conversas.\n\nSeu trabalho √©:\n1. Detectar o humor geral do dia (escala 1-10)\n2. Avaliar o n√≠vel de energia (escala 1-10)\n3. confianca_analise de 0 a 100\n4. Identificar varia√ß√µes durante a conversa\n5. Capturar per√≠odo do dia se mencionado\n\nSeja objetivo, baseie-se apenas no texto real, e justifique suas avalia√ß√µes de forma breve.\n\nRetorne SEMPRE um JSON v√°lido com a estrutura exata solicitada.",
          "maxIterations": 3
        }
      },
      "id": "agent-humor",
      "name": "4. Analisar Humor/Energia",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [960, 600]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 1000,
          "temperature": 0.2
        }
      },
      "id": "llm-humor",
      "name": "LLM Humor",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [880, 820],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"humor_dia\": 4,\n  \"energia_nivel\": 6,\n  \"variacao_humor\": \"descendente\",\n  \"variacao_energia\": \"estavel\",\n  \"periodo_dia\": \"tarde\",\n  \"justificativa_humor\": \"Usu√°rio come√ßou o dia produtivo e animado, mas ao final relata tristeza profunda, ang√∫stia e desmotiva√ß√£o ap√≥s ver fotos da ex-mulher\",\n  \"justificativa_energia\": \"Menciona que caminhou bastante, fez almo√ßo, trabalhou no app - energia moderada/boa, mas manteve disposi√ß√£o f√≠sica apesar da queda emocional\",\n  \"evidencias_textuais\": [\n    \"dia estava muito bom hoje, muito produtivo\",\n    \"estava disposto, animado\",\n    \"bateu uma coisa muito ruim\",\n    \"ang√∫stia, uma tristeza muito grande\",\n    \"muito desmotivado e desanimado\"\n  ],\n  \"confianca_analise\": 95\n}",
        "autoFix": true
      },
      "id": "parser-humor",
      "name": "Parser Humor",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [1040, 820]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO usuarios_humor_energia (\n  usuario_id,\n  chat_id,\n  data_registro,\n  hora_registro,\n  periodo_dia,\n  humor_dia,\n  energia_nivel,\n  variacao_humor,\n  variacao_energia,\n  justificativa_humor,\n  justificativa_energia,\n  evidencias_textuais,\n  confianca_analise\n)\nVALUES (\n  $1::uuid,\n  $2::uuid,\n  $3::date,\n  CURRENT_TIME,\n  $4::varchar(20),\n  $5::integer,\n  $6::integer,\n  $7::varchar(20),\n  $8::varchar(20),\n  $9::text,\n  $10::text,\n  $11::jsonb,\n  $12::integer\n)\nRETURNING id, humor_dia, energia_nivel;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.usuario_id,\n  $('start').first().json.chat_id,\n  ((v) => v ? new Date(v).toISOString().slice(0,10) : null)($('start').first().json.data_conversa),\n  $json.output.periodo_dia,\n  $json.output.humor_dia,\n  $json.output.energia_nivel,\n  $json.output.variacao_humor,\n  $json.output.variacao_energia,\n  JSON.stringify($json.output.justificativa_humor),\n  JSON.stringify($json.output.justificativa_energia),\n  JSON.stringify($json.output.evidencias_textuais || []),\n  $json.output.confianca_analise\n] }}"
        }
      },
      "id": "pg-gravar-humor",
      "name": "Gravar Humor",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [1200, 600],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "HDTrSrJiBIv2FFks",
          "mode": "list",
          "cachedResultUrl": "/workflow/HDTrSrJiBIv2FFks",
          "cachedResultName": "sw_get_history"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "usr_id": "={{ $('start').first().json.usuario_id }}"
          }
        },
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "id": "sw-get-history",
      "name": "Buscar Hist√≥rico BigFive",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.3,
      "position": [960, 800],
      "alwaysOutputData": true
    },
    {
      "parameters": {
        "functionCode": "const startData = $items('start')[0]?.json ?? {};\nconst historyItems = $items('Buscar Hist√≥rico BigFive').map((item) => item.json).filter(Boolean);\nconst formatDate = (value) => {\n  if (!value) return null;\n  const parsed = new Date(value);\n  if (Number.isNaN(parsed.getTime())) return value;\n  return parsed.toISOString().slice(0, 10);\n};\nconst historicoOrdenado = historyItems\n  .map((entry) => ({\n    data: formatDate(entry.data_conversa),\n    resumo: entry.resumo_conversa ?? ''\n  }))\n  .filter((entry) => entry.data || entry.resumo)\n  .sort((a, b) => {\n    if (!a.data || !b.data) return 0;\n    return a.data < b.data ? 1 : -1;\n  });\nconst historicoResumo = historicoOrdenado.length\n  ? historicoOrdenado\n      .map((entry) => `- ${entry.data ?? 'data indeterminada'}: ${entry.resumo || 'sem resumo dispon√≠vel'}`)\n      .join('\\n')\n  : 'Sem hist√≥rico relevante nos √∫ltimos 5 dias.';\nreturn [\n  {\n    json: {\n      ...startData,\n      historico_resumo: historicoResumo,\n      historico_itens: historicoOrdenado\n    }\n  }\n];"
      },
      "id": "code-preparar-bigfive",
      "name": "Preparar Contexto BigFive",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1200, 800]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Use a conversa ATUAL como fonte principal e estime o perfil Big Five (OCEAN), tratando o hist√≥rico recente apenas como contexto complementar.\n\n**HIST√ìRICO (resumos √∫ltimos 5 dias):**\n{{ $json.historico_resumo }}\n\n**CONVERSA ATUAL (JSON):**\n```json\n{{ $json.mensagens }}\n```\n**Nome do usu√°rio:** {{ $json.usr_nome_preferencia }}\n\n**SEU OBJETIVO**\n1) Identificar sinais claros e textuais na conversa atual para cada tra√ßo: Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism.\n2) Atribuir **score 0-100** por tra√ßo (escala cont√≠nua; 50 = neutro/mediano).\n3) Extrair **EVID√äNCIAS** em 2-4 trechos curtos (m√°x. 15 palavras cada) da conversa atual para cada tra√ßo.\n4) Estimar **confiabilidade (0-100)** por tra√ßo, baseada na quantidade/clareza das evid√™ncias.\n5) Determinar **perfil_primario** = tra√ßo com maior score (se diferen√ßa <5 pontos entre o 1¬∫ e 2¬∫, retorne \"misto\").\n6) Produzir um **resumo_perfil** (m√°x. 400 caracteres) em linguagem acess√≠vel e n√£o-cl√≠nica, coerente com o MindQuest.\n7) Se as evid√™ncias forem insuficientes para qualquer tra√ßo, retorne score=50 e confiabilidade ‚â§ 40 para aquele tra√ßo.\n\n**REGRAS CR√çTICAS**\n- Leia APENAS mensagens com `autor = \"usuario\"` da conversa atual.\n- Utilize o hist√≥rico somente para reconhecer padr√µes, mas N√ÉO use trechos do hist√≥rico como evid√™ncia literal.\n- **Pro√≠ba suposi√ß√µes**: n√£o invente fatos n√£o ditos; use somente trechos literais da conversa atual.\n- **Escala obrigat√≥ria 0-100** para scores e confiabilidade.\n- Mantenha sa√≠das em **portugu√™s**.\n- **N√ÉO** fa√ßa diagn√≥sticos cl√≠nicos. Foco descritivo, orientado a autoconhecimento.\n- Retorne **APENAS JSON v√°lido**, no formato definido em \"FORMATO DE SA√çDA\".\n\n**CRIT√âRIOS DE INTERPRETA√á√ÉO (guia resumido)**\n- **Openness (Abertura):** curiosidade, ideias novas, explorar possibilidades; baixo: prefer√™ncia por rotina.\n- **Conscientiousness (Conscienciosidade):** organiza√ß√£o, disciplina, plano/execu√ß√£o; baixo: impulsividade, procrastina√ß√£o.\n- **Extraversion (Extrovers√£o):** energia social, busca de est√≠mulos/contato; baixo: reserva, foco interno.\n- **Agreeableness (Amabilidade):** empatia, coopera√ß√£o; baixo: assertividade dura, conflito, ceticismo.\n- **Neuroticism (Neuroticismo):** sensibilidade a estresse, ansiedade/rumina√ß√£o; baixo: estabilidade emocional.\n\n**FORMATO DE SA√çDA (JSON):**\n{\n  \"big_five\": {\n    \"openness\": {\n      \"score\": 0,\n      \"confiabilidade\": 0,\n      \"evidencias\": [\"...\", \"...\"]\n    },\n    \"conscientiousness\": {\n      \"score\": 0,\n      \"confiabilidade\": 0,\n      \"evidencias\": [\"...\", \"...\"]\n    },\n    \"extraversion\": {\n      \"score\": 0,\n      \"confiabilidade\": 0,\n      \"evidencias\": [\"...\", \"...\"]\n    },\n    \"agreeableness\": {\n      \"score\": 0,\n      \"confiabilidade\": 0,\n      \"evidencias\": [\"...\", \"...\"]\n    },\n    \"neuroticism\": {\n      \"score\": 0,\n      \"confiabilidade\": 0,\n      \"evidencias\": [\"...\", \"...\"]\n    }\n  },\n  \"perfil_primario\": \"openness|conscientiousness|extraversion|agreeableness|neuroticism|misto\",\n  \"resumo_perfil\": \"texto curto e n√£o cl√≠nico\",\n  \"insuficiente\": false\n}\n\n**NOTAS DE QUALIDADE**\n- Se a conversa for pobre em pistas, defina `insuficiente = true` e mantenha scores pr√≥ximos de 50 com baixa confiabilidade.\n- \"Evid√™ncias\" DEVEM ser trechos literais e curtos da conversa atual (n√£o use o hist√≥rico).",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "Voc√™ √© um assistente especialista em Big Five (OCEAN) e √©tica em IA. Sua fun√ß√£o √© inferir tend√™ncias de personalidade com base EXCLUSIVAMENTE em trechos literais do usu√°rio. Siga estes princ√≠pios:\n1) Precis√£o e parcim√¥nia: sem extrapola√ß√µes. Use apenas o que est√° escrito.\n2) Transpar√™ncia: inclua evid√™ncias curtas (2-4) por tra√ßo.\n3) Escalas cont√≠nuas 0-100 para score e confiabilidade (50 = neutro; 0-20 muito baixo; 80-100 muito alto).\n4) Comunica√ß√£o respons√°vel: linguagem acess√≠vel, n√£o cl√≠nica, acolhedora.\n5) Se faltarem sinais para um tra√ßo, use score=50, confiabilidade ‚â§ 40 e marque `insuficiente=true` se a conversa inteira n√£o sustentar infer√™ncia.\nRetorne SEMPRE JSON v√°lido no formato solicitado.",
          "maxIterations": 3
        }
      },
      "id": "agent-bigfive",
      "name": "5. Analisar Big Five",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [1440, 800]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 2000,
          "temperature": 0.2
        }
      },
      "id": "llm-bigfive",
      "name": "LLM BigFive",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [1360, 1020],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"big_five\": {\n    \"openness\": {\"score\": 62, \"confiabilidade\": 78, \"evidencias\": [\"gosto de explorar ideias novas\", \"procuro alternativas criativas\"]},\n    \"conscientiousness\": {\"score\": 54, \"confiabilidade\": 65, \"evidencias\": [\"monitorei meu plano\", \"organizei meus passos\"]},\n    \"extraversion\": {\"score\": 41, \"confiabilidade\": 60, \"evidencias\": [\"prefiro ficar na minha\", \"evitei encontros\"]},\n    \"agreeableness\": {\"score\": 70, \"confiabilidade\": 72, \"evidencias\": [\"procurei conciliar\", \"quero evitar conflito\"]},\n    \"neuroticism\": {\"score\": 58, \"confiabilidade\": 68, \"evidencias\": [\"fiquei ansioso com perdas\", \"preocupa√ß√£o constante\"]}\n  },\n  \"perfil_primario\": \"agreeableness\",\n  \"resumo_perfil\": \"Pessoa colaborativa, aberta a di√°logos e solu√ß√µes conjuntas, mantendo equil√≠brio em disciplina e energia social.\",\n  \"insuficiente\": false\n}",
        "autoFix": true
      },
      "id": "parser-bigfive",
      "name": "Parser BigFive",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [1520, 1020]
    },
    {
      "parameters": {
        "functionCode": "const startItem = $items(\"start\")[0]?.json ?? {};\nconst preparado = $items(\"Preparar Contexto BigFive\")[0]?.json ?? {};\nconst payload = $json.output ?? {};\nconst traits = ['openness','conscientiousness','extraversion','agreeableness','neuroticism'];\nconst scores = traits.map((key) => {\n  const data = payload.big_five?.[key] ?? {};\n  const score = Number(data.score);\n  const confianca = Number(data.confiabilidade);\n  return {\n    id: key,\n    score: Number.isFinite(score) ? score : null,\n    confiabilidade: Number.isFinite(confianca) ? confianca : null\n  };\n});\nconst sorted = [...scores].sort((a, b) => (b.score ?? 0) - (a.score ?? 0));\nconst validTraits = new Set(traits);\nconst originalPrimary = payload.perfil_primario ?? null;\nlet primary = originalPrimary;\nif (!primary || primary === 'misto' || !validTraits.has(primary)) {\n  primary = sorted[0]?.id ?? null;\n}\nlet secondary = sorted.find((entry) => entry.id !== primary)?.id ?? null;\nif (!secondary && sorted[1]) {\n  secondary = sorted[1].id;\n}\nconst sumConfianca = scores.reduce((acc, entry) => acc + (entry.confiabilidade ?? 0), 0);\nconst confiancaMedia = scores.length ? Math.round(sumConfianca / scores.length) : null;\nconst rawDate = startItem.data_conversa || preparado.data_conversa;\nlet dataConversa = null;\nif (rawDate) {\n  const parsed = new Date(rawDate);\n  if (!isNaN(parsed)) {\n    dataConversa = parsed.toISOString().slice(0, 10);\n  }\n}\nif (!dataConversa) {\n  const now = new Date();\n  dataConversa = now.toISOString().slice(0, 10);\n}\nconst result = {\n  usuario_id: startItem.usuario_id ?? null,\n  chat_id: startItem.chat_id ?? null,\n  data_conversa: dataConversa,\n  perfil_original: originalPrimary,\n  perfil_primario: primary,\n  perfil_secundario: secondary,\n  resumo_perfil: payload.resumo_perfil ?? null,\n  insuficiente: Boolean(payload.insuficiente),\n  confianca_media: confiancaMedia,\n  raw_resposta: payload\n};\nfor (const trait of traits) {\n  const data = payload.big_five?.[trait] ?? {};\n  const score = Number(data.score);\n  const confianca = Number(data.confiabilidade);\n  result[`score_${trait}`] = Number.isFinite(score) ? score : null;\n  result[`confianca_${trait}`] = Number.isFinite(confianca) ? confianca : null;\n}\nreturn [{ json: result }];"
      },
      "id": "code-preparar-registro-bigfive",
      "name": "Preparar Registro BigFive",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1680, 800]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO usuarios_perfis (\n  usuario_id,\n  chat_id,\n  data_conversa,\n  perfil_original,\n  perfil_primario,\n  perfil_secundario,\n  resumo_perfil,\n  insuficiente,\n  score_openness,\n  score_conscientiousness,\n  score_extraversion,\n  score_agreeableness,\n  score_neuroticism,\n  confianca_openness,\n  confianca_conscientiousness,\n  confianca_extraversion,\n  confianca_agreeableness,\n  confianca_neuroticism,\n  confianca_media,\n  raw_resposta,\n  criado_em,\n  atualizado_em\n)\nVALUES (\n  $1::uuid,\n  $2::uuid,\n  $3::date,\n  $4::varchar,\n  $5::varchar,\n  $6::varchar,\n  $7::text,\n  $8::boolean,\n  $9::integer,\n  $10::integer,\n  $11::integer,\n  $12::integer,\n  $13::integer,\n  $14::integer,\n  $15::integer,\n  $16::integer,\n  $17::integer,\n  $18::integer,\n  $19::integer,\n  $20::jsonb,\n  NOW(),\n  NOW()\n)\nON CONFLICT (chat_id) DO UPDATE SET\n  perfil_original = EXCLUDED.perfil_original,\n  perfil_primario = EXCLUDED.perfil_primario,\n  perfil_secundario = EXCLUDED.perfil_secundario,\n  resumo_perfil = EXCLUDED.resumo_perfil,\n  insuficiente = EXCLUDED.insuficiente,\n  score_openness = EXCLUDED.score_openness,\n  score_conscientiousness = EXCLUDED.score_conscientiousness,\n  score_extraversion = EXCLUDED.score_extraversion,\n  score_agreeableness = EXCLUDED.score_agreeableness,\n  score_neuroticism = EXCLUDED.score_neuroticism,\n  confianca_openness = EXCLUDED.confianca_openness,\n  confianca_conscientiousness = EXCLUDED.confianca_conscientiousness,\n  confianca_extraversion = EXCLUDED.confianca_extraversion,\n  confianca_agreeableness = EXCLUDED.confianca_agreeableness,\n  confianca_neuroticism = EXCLUDED.confianca_neuroticism,\n  confianca_media = EXCLUDED.confianca_media,\n  raw_resposta = EXCLUDED.raw_resposta,\n  atualizado_em = NOW()\nRETURNING id, perfil_primario;",
        "options": {
          "queryReplacement": "={{ [\n  $json.usuario_id ?? null,\n  $json.chat_id ?? null,\n  $json.data_conversa ?? null,\n  $json.perfil_original ?? null,\n  $json.perfil_primario ?? null,\n  $json.perfil_secundario ?? null,\n  $json.resumo_perfil ?? null,\n  $json.insuficiente === true,\n  $json.score_openness ?? null,\n  $json.score_conscientiousness ?? null,\n  $json.score_extraversion ?? null,\n  $json.score_agreeableness ?? null,\n  $json.score_neuroticism ?? null,\n  $json.confianca_openness ?? null,\n  $json.confianca_conscientiousness ?? null,\n  $json.confianca_extraversion ?? null,\n  $json.confianca_agreeableness ?? null,\n  $json.confianca_neuroticism ?? null,\n  $json.confianca_media ?? null,\n  $json.raw_resposta ?? {}\n] }}"
        }
      },
      "id": "pg-gravar-bigfive",
      "name": "Gravar BigFive",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [1920, 800],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "promptType": "define",
        "text": "=Voc√™ √© psic√≥logo especialista em desenvolvimento pessoal. Analise a conversa e contexto validado abaixo.\n\nCONVERSA:\n{{ $('start').first().json.mensagens }}\n\nUsu√°rio: {{ $('start').first().json.usr_nome_preferencia }} | Data: {{ $('start').first().json.data_conversa }}\n\nChame a ferramenta: ¬¥get_user_insight`\nConsidere tamb√©m esses ultimos Insights na sua analise\n\nTAREFA: Gere 1 insights acion√°veis com Feedback Sandu√≠che + Recursos Pr√°ticos.\nPriorize os pontos mais relevantes identificados na conversa\n\nAnalise os ultimos Insighs anteriores para evitar repeti√ß√£o\n\nESTRUTURA DE CADA INSIGHT:\n1. RESUMO (30-50 palavras): Sintetize estado emocional objetivamente\n2. FEEDBACK SANDU√çCHE:\n   - Positivo (20-30 pal): Reconhe√ßa for√ßas\n   - Desenvolvimento (30-40 pal): Padr√£o que merece aten√ß√£o\n   - Motivacional (20-30 pal): Esperan√ßa + pr√≥ximos passos\n3. RECURSOS (2-4 itens): tipo, nome, descricao, aplicacao_pratica\n4. TITULO: Gere titulo curto 3 a 4 palavras. use tecnicas de copy do marketing para gerar curiosidade e e headlines clic√°veis.\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n‚ö†Ô∏è VALORES PERMITIDOS - USE EXATAMENTE COMO LISTADO ‚ö†Ô∏è\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nCATEGORIA (use APENAS estes valores):\n‚úì comportamental\n‚úì emocional\n‚úì social\n‚úì cognitivo\n‚úó NUNCA: financeiro, profissional, financeiro-emocional, ou qualquer outro\n\nTIPO INSIGHT (use APENAS estes valores):\n‚úì padrao\n‚úì melhoria\n‚úì positivo\n‚úì alerta\n\nPRIORIDADE (use APENAS estes valores):\n‚úì alta\n‚úì media (SEM acento)\n‚úì baixa\n\nTIPO RECURSO (use APENAS estes valores):\n‚úì tecnica\n‚úì conceito\n‚úì leitura\n‚úì pratica\n‚úì reflexao\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nREGRAS CR√çTICAS:\n- Base TUDO no relatado (sem suposi√ß√µes)\n- Use APENAS os valores listados acima (sem varia√ß√µes, adapta√ß√µes ou combina√ß√µes)\n- Seja ESPEC√çFICO nas evid√™ncias\n- Recursos PR√ÅTICOS e aplic√°veis\n- Tom EMP√ÅTICO mas DIRETO\n- VALIDE cada campo antes de gerar o JSON\n\nANTES DE RETORNAR: Verifique se TODOS os valores de categoria, tipo, prioridade e tipo_recurso est√£o EXATAMENTE como listado acima.\n\nRETORNE JSON ARRAY com 1 insights no formato:\n[{\"tipo\":\"padrao\",\"categoria\":\"emocional\",\"titulo\":\"T√≠tulo\",\"icone\":\"üîÑ\",\"prioridade\":\"alta\",\"resumo_situacao\":\"...\",\"feedback_positivo\":\"...\",\"feedback_desenvolvimento\":\"...\",\"feedback_motivacional\":\"...\",\"recursos_sugeridos\":[{\"tipo\":\"tecnica\",\"nome\":\"...\",\"descricao\":\"...\",\"aplicacao_pratica\":\"...\"}],\"baseado_em\":[\"evid√™ncia1\",\"evid√™ncia2\"]}]",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "Psic√≥logo especialista. Gera insights acion√°veis com feedback sandu√≠che e recursos pr√°ticos. Retorna array JSON com 2-4 insights.",
          "maxIterations": 3
        }
      },
      "id": "agent-insights",
      "name": "6. Gerar Insights",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [960, 1000]
    },
    {
      "parameters": {
        "options": {
          "maxTokens": 2000,
          "temperature": 0.3
        }
      },
      "id": "llm-insights",
      "name": "LLM Insights",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [880, 1220],
      "credentials": {
        "openRouterApi": {
          "id": "rSnkOnnAHyfayLJt",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsonSchemaExample": "[{\"tipo\":\"padrao\",\"categoria\":\"emocional\",\"titulo\":\"Ciclo Produtividade\",\"icone\":\"üîÑ\",\"prioridade\":\"media\",\"resumo_situacao\":\"Resumo\",\"feedback_positivo\":\"Positivo\",\"feedback_desenvolvimento\":\"Desenvolvimento\",\"feedback_motivacional\":\"Motivacional\",\"recursos_sugeridos\":[{\"tipo\":\"tecnica\",\"nome\":\"Nome\",\"descricao\":\"Desc\",\"aplicacao_pratica\":\"Aplica√ß√£o\"}],\"baseado_em\":[\"ev1\"]}]",
        "autoFix": true
      },
      "id": "parser-insights",
      "name": "Parser Insights",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [1040, 1220]
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "select tipo, categoria, titulo, descricao, prioridade from insights where usuario_id = $1 limit 15 ",
        "options": {
          "queryReplacement": "={{ $('start').first().json.usuario_id }}"
        }
      },
      "id": "tool-get-insights",
      "name": "get_user_insight",
      "type": "n8n-nodes-base.postgresTool",
      "typeVersion": 2.6,
      "position": [1120, 1220],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "INSERT INTO insights (\n  usuario_id,\n  chat_id,\n  tipo,\n  categoria,\n  titulo,\n  descricao,\n  icone,\n  prioridade,\n  ativo,\n  resumo_situacao,\n  feedback_positivo,\n  feedback_desenvolvimento,\n  feedback_motivacional,\n  recursos_sugeridos,\n  baseado_em\n)\nSELECT \n  $1::uuid,\n  $2::uuid,\n  elem->>'tipo',\n  elem->>'categoria',\n  elem->>'titulo',\n  elem->>'resumo_situacao',\n  elem->>'icone',\n  elem->>'prioridade',\n  true,\n  elem->>'resumo_situacao',\n  elem->>'feedback_positivo',\n  elem->>'feedback_desenvolvimento',\n  elem->>'feedback_motivacional',\n  elem->'recursos_sugeridos',\n  ARRAY(SELECT jsonb_array_elements_text(elem->'baseado_em'))\nFROM jsonb_array_elements($3::jsonb) AS elem\nRETURNING id, tipo, categoria, titulo, prioridade;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.usuario_id,\n  $('start').first().json.chat_id,\n  JSON.stringify($json.output || [])\n] }}"
        }
      },
      "id": "pg-gravar-insights",
      "name": "Gravar Insights",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [1200, 1000],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "id": "merge-experts",
      "name": "Merge Experts",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.1,
      "position": [1700, 500]
    },

    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Atualizar usr_chat com resumo e status\nUPDATE usr_chat SET\n  resumo_conversa = $2,\n  tem_reflexao = $3,\n  total_palavras_usuario = COALESCE(total_palavras_usuario, 0) + $4,\n  status = 'finalizado',\n  horario_fim = NOW(),\n  atualizado_em = NOW()\nWHERE id = $1::uuid\nRETURNING id, status;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.chat_id,\n  $('1. Resumo Conversa').first().json.output.resumo_atualizado,\n  $('1. Resumo Conversa').first().json.output.tem_reflexao,\n  $('1. Resumo Conversa').first().json.output.total_palavras_delta || 0\n] }}"
        }
      },
      "id": "pg-atualizar-chat",
      "name": "Atualizar usr_chat",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [1940, 500],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Registrar processamento final no log_experts\nINSERT INTO log_experts (usuario_id, chat_id, expert_name, ultima_interaction, historico, criado_em, atualizado_em)\nVALUES (\n  $1::uuid,\n  $2::uuid,\n  'sw_experts_v2',\n  $3::int,\n  jsonb_build_array(jsonb_build_object(\n    'de', 0,\n    'ate', $3::int,\n    'novas', $3::int,\n    'em', NOW(),\n    'tem_contexto', $4::boolean,\n    'tem_reflexao', $5::boolean,\n    'experts_executados', ARRAY['resumo','sabotadores','panas','humor','bigfive','insights']\n  )),\n  NOW(),\n  NOW()\n)\nON CONFLICT (chat_id, expert_name) DO UPDATE SET\n  historico = log_experts.historico || jsonb_build_array(jsonb_build_object(\n    'de', log_experts.ultima_interaction,\n    'ate', $3::int,\n    'novas', $3::int - log_experts.ultima_interaction,\n    'em', NOW(),\n    'tem_contexto', $4::boolean,\n    'tem_reflexao', $5::boolean,\n    'experts_executados', ARRAY['resumo','sabotadores','panas','humor','bigfive','insights']\n  )),\n  ultima_interaction = $3::int,\n  atualizado_em = NOW()\nRETURNING id;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.usuario_id,\n  $('start').first().json.chat_id,\n  $('start').first().json.total_interactions,\n  $('1. Resumo Conversa').first().json.output.tem_contexto,\n  $('1. Resumo Conversa').first().json.output.tem_reflexao\n] }}"
        }
      },
      "id": "pg-log-final",
      "name": "Registrar Log Final",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [2160, 500],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "operation": "executeQuery",
        "query": "-- Atualizar apenas resumo quando n√£o tem contexto\nUPDATE usr_chat SET\n  resumo_conversa = $2,\n  atualizado_em = NOW()\nWHERE id = $1::uuid\nRETURNING id;",
        "options": {
          "queryReplacement": "={{ [\n  $('start').first().json.chat_id,\n  $('1. Resumo Conversa').first().json.output.resumo_atualizado\n] }}"
        }
      },
      "id": "pg-atualizar-sem-contexto",
      "name": "Atualizar Resumo (sem contexto)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.6,
      "position": [960, 1200],
      "credentials": {
        "postgres": {
          "id": "8ySWxtSO7gYK5uue",
          "name": "Postgres account"
        }
      }
    },

    {
      "parameters": {
        "jsCode": "// Retorna resultado final\nconst analise = $('1. Resumo Conversa').first().json.output;\nconst start = $('start').first().json;\n\nreturn [{\n  json: {\n    success: true,\n    usuario_id: start.usuario_id,\n    chat_id: start.chat_id,\n    tem_contexto: analise.tem_contexto,\n    tem_reflexao: analise.tem_reflexao,\n    experts_executados: analise.tem_contexto \n      ? ['resumo','sabotadores','panas','humor','bigfive','insights']\n      : ['resumo']\n  }\n}];"
      },
      "id": "code-resultado-final",
      "name": "Resultado Final",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2380, 500]
    }
  ],
  "connections": {
    "start": {
      "main": [[{ "node": "Buscar Dados Chat", "type": "main", "index": 0 }]]
    },
    "Buscar Dados Chat": {
      "main": [[{ "node": "1. Resumo Conversa", "type": "main", "index": 0 }]]
    },
    "LLM Resumo": {
      "ai_languageModel": [[{ "node": "1. Resumo Conversa", "type": "ai_languageModel", "index": 0 }]]
    },
    "Parser Resumo": {
      "ai_outputParser": [[{ "node": "1. Resumo Conversa", "type": "ai_outputParser", "index": 0 }]]
    },
    "1. Resumo Conversa": {
      "main": [[{ "node": "Tem Contexto?", "type": "main", "index": 0 }]]
    },
    
    "Tem Contexto?": {
      "main": [
        [
          { "node": "Buscar Cat√°logo Sabotadores", "type": "main", "index": 0 },
          { "node": "3. Analisar Emo√ß√µes PANAS", "type": "main", "index": 0 },
          { "node": "4. Analisar Humor/Energia", "type": "main", "index": 0 },
          { "node": "Buscar Hist√≥rico BigFive", "type": "main", "index": 0 },
          { "node": "6. Gerar Insights", "type": "main", "index": 0 }
        ],
        [
          { "node": "Atualizar Resumo (sem contexto)", "type": "main", "index": 0 }
        ]
      ]
    },

    "Buscar Cat√°logo Sabotadores": {
      "main": [[{ "node": "2. Analisar Sabotadores", "type": "main", "index": 0 }]]
    },
    "LLM Sabotadores": {
      "ai_languageModel": [[{ "node": "2. Analisar Sabotadores", "type": "ai_languageModel", "index": 0 }]]
    },
    "Parser Sabotadores": {
      "ai_outputParser": [[{ "node": "2. Analisar Sabotadores", "type": "ai_outputParser", "index": 0 }]]
    },
    "2. Analisar Sabotadores": {
      "main": [[{ "node": "Gravar Sabotadores", "type": "main", "index": 0 }]]
    },
    "Gravar Sabotadores": {
      "main": [[{ "node": "Merge Experts", "type": "main", "index": 0 }]]
    },

    "LLM PANAS": {
      "ai_languageModel": [[{ "node": "3. Analisar Emo√ß√µes PANAS", "type": "ai_languageModel", "index": 0 }]]
    },
    "Parser PANAS": {
      "ai_outputParser": [[{ "node": "3. Analisar Emo√ß√µes PANAS", "type": "ai_outputParser", "index": 0 }]]
    },
    "3. Analisar Emo√ß√µes PANAS": {
      "main": [[{ "node": "Gravar Emo√ß√µes", "type": "main", "index": 0 }]]
    },
    "Gravar Emo√ß√µes": {
      "main": [[{ "node": "Merge Experts", "type": "main", "index": 1 }]]
    },

    "LLM Humor": {
      "ai_languageModel": [[{ "node": "4. Analisar Humor/Energia", "type": "ai_languageModel", "index": 0 }]]
    },
    "Parser Humor": {
      "ai_outputParser": [[{ "node": "4. Analisar Humor/Energia", "type": "ai_outputParser", "index": 0 }]]
    },
    "4. Analisar Humor/Energia": {
      "main": [[{ "node": "Gravar Humor", "type": "main", "index": 0 }]]
    },
    "Gravar Humor": {
      "main": [[{ "node": "Merge Experts", "type": "main", "index": 2 }]]
    },

    "Buscar Hist√≥rico BigFive": {
      "main": [[{ "node": "Preparar Contexto BigFive", "type": "main", "index": 0 }]]
    },
    "Preparar Contexto BigFive": {
      "main": [[{ "node": "5. Analisar Big Five", "type": "main", "index": 0 }]]
    },
    "LLM BigFive": {
      "ai_languageModel": [[{ "node": "5. Analisar Big Five", "type": "ai_languageModel", "index": 0 }]]
    },
    "Parser BigFive": {
      "ai_outputParser": [[{ "node": "5. Analisar Big Five", "type": "ai_outputParser", "index": 0 }]]
    },
    "5. Analisar Big Five": {
      "main": [[{ "node": "Preparar Registro BigFive", "type": "main", "index": 0 }]]
    },
    "Preparar Registro BigFive": {
      "main": [[{ "node": "Gravar BigFive", "type": "main", "index": 0 }]]
    },
    "Gravar BigFive": {
      "main": [[{ "node": "Merge Experts", "type": "main", "index": 3 }]]
    },

    "LLM Insights": {
      "ai_languageModel": [[{ "node": "6. Gerar Insights", "type": "ai_languageModel", "index": 0 }]]
    },
    "Parser Insights": {
      "ai_outputParser": [[{ "node": "6. Gerar Insights", "type": "ai_outputParser", "index": 0 }]]
    },
    "get_user_insight": {
      "ai_tool": [[{ "node": "6. Gerar Insights", "type": "ai_tool", "index": 0 }]]
    },
    "6. Gerar Insights": {
      "main": [[{ "node": "Gravar Insights", "type": "main", "index": 0 }]]
    },
    "Gravar Insights": {
      "main": [[{ "node": "Merge Experts", "type": "main", "index": 4 }]]
    },

    "Merge Experts": {
      "main": [[{ "node": "Atualizar usr_chat", "type": "main", "index": 0 }]]
    },
    "Atualizar usr_chat": {
      "main": [[{ "node": "Registrar Log Final", "type": "main", "index": 0 }]]
    },
    "Registrar Log Final": {
      "main": [[{ "node": "Resultado Final", "type": "main", "index": 0 }]]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner"
  },
  "pinData": {
    "start": [
      {
        "json": {
          "usuario_id": "d949d81c-9235-41ce-8b3b-6b5d593c5e24",
          "chat_id": "fae2c26e-ec33-4bb5-979d-1af6f2bd2068",
          "mensagens": "[{\"interaction\":1,\"autor\":\"usuario\",\"texto\":\"Hoje acordei pensando muito no meu trabalho e nas decis√µes que preciso tomar. Me sinto ansioso com a situa√ß√£o financeira.\",\"timestamp\":\"2025-12-12T10:00:00.000Z\"},{\"interaction\":1,\"autor\":\"agente\",\"texto\":\"Entendo sua preocupa√ß√£o. Quer me contar mais sobre essas decis√µes?\",\"timestamp\":\"2025-12-12T10:01:00.000Z\"},{\"interaction\":2,\"autor\":\"usuario\",\"texto\":\"Preciso decidir se continuo investindo no meu projeto ou se procuro um emprego. Tenho medo de fracassar, mas tamb√©m n√£o quero desistir do meu sonho.\",\"timestamp\":\"2025-12-12T10:02:00.000Z\"}]",
          "data_conversa": "2025-12-12",
          "usr_nome_preferencia": "Aldo",
          "total_interactions": 4
        }
      }
    ]
  }
}
